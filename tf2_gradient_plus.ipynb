{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隐藏层1张量 \n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1)) \n",
    "b1 = tf.Variable(tf.zeros([256])) \n",
    "# 隐藏层2张量 \n",
    "w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1)) \n",
    "b2 = tf.Variable(tf.zeros([128])) \n",
    "# 隐藏层3张量 \n",
    "w3 = tf.Variable(tf.random.truncated_normal([128, 64], stddev=0.1)) \n",
    "b3 = tf.Variable(tf.zeros([64])) \n",
    "# 输出层张量 \n",
    "w4 = tf.Variable(tf.random.truncated_normal([64, 10], stddev=0.1)) \n",
    "b4 = tf.Variable(tf.zeros([10])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones([10,28*28])\n",
    "with tf.GradientTape() as tape: # 梯度记录器\n",
    "    # x: [b, 28*28] \n",
    "    #  隐藏层1前向计算，[b, 28*28] => [b, 256] \n",
    "    h1 = tf.matmul(x,w1) + tf.broadcast_to(b1, [x.shape[0], 256]) \n",
    "    h1 = tf.nn.relu(h1) \n",
    "    # 隐藏层2前向计算，[b, 256] => [b, 128] \n",
    "    h2 = tf.matmul(h1,w2) + b2 \n",
    "    h2 = tf.nn.relu(h2) \n",
    "    # 隐藏层3前向计算，[b, 128] => [b, 64]  \n",
    "    h3 = tf.matmul(h2,w3) + b3 \n",
    "    h3 = tf.nn.relu(h3) \n",
    "    # 输出层前向计算，[b, 64] => [b, 10]  \n",
    "    h4 = tf.matmul(h3,w4) + b4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=134, shape=(3,), dtype=float32, numpy=array([0.6590012, 0.242433 , 0.0985659], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = tf.constant([2.,1.,0.1]) \n",
    "tf.nn.softmax(z) # 通过Softmax函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=180, shape=(), dtype=float32, numpy=1.7105124>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = tf.random.normal([2,10]) # 构造输出层的输出 \n",
    "y_onehot = tf.constant([1,3]) # 构造真实值 \n",
    "y_onehot = tf.one_hot(y_onehot, depth=10) # one-hot编码 \n",
    "# 输出层未使用Softmax函数，故from_logits设置为True \n",
    "# 这样categorical_crossentropy函数在计算损失函数前，会先内部调用Softmax函数 \n",
    "loss = tf.keras.losses.categorical_crossentropy(y_onehot,z,from_logits=True) \n",
    "loss = tf.reduce_mean(loss) # 计算平均交叉熵损失 \n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=140, shape=(2, 10), dtype=float32, numpy=\n",
       "array([[ 1.0383689 ,  0.94670373, -1.3206798 , -0.06417084, -0.5799421 ,\n",
       "         0.35431355,  0.01397425, -2.443613  ,  1.6363698 ,  1.4580986 ],\n",
       "       [-0.66133857, -1.5434911 , -0.04669975,  1.6061795 ,  1.804766  ,\n",
       "         1.5559579 ,  0.45376658, -1.4544407 , -0.66890866, -0.29723737]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=230, shape=(), dtype=float32, numpy=1.7105124>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建Softmax与交叉熵计算类，输出层的输出z未使用softmax \n",
    "criteon = tf.keras.losses.CategoricalCrossentropy(from_logits=True) \n",
    "loss = criteon(y_onehot,z) # 计算损失 \n",
    "loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=244, shape=(2,), dtype=float32, numpy=array([0.39007244, 1.5059801 ], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = tf.random.normal([2,10]) # 构造网络输出 \n",
    "y_onehot = tf.constant([1,3]) # 构造真实值 \n",
    "y_onehot = tf.one_hot(y_onehot, depth=10) \n",
    "loss = tf.keras.losses.MSE(y_onehot, o) # 计算均方差 \n",
    "loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
