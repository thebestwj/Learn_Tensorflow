{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12634716710723773710\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1453034700\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3988732016876304360\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 750 Ti, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(x_trainx, y_train), (x_testx, y_test) = mnist\n",
    "\n",
    "x_train = np.reshape(x_trainx,(60000,784))\n",
    "x_test = np.reshape(x_testx,(10000,784))\n",
    "\n",
    "#regulazation\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "y_train = np.eye(10)[y_train]\n",
    "y_test = np.eye(10)[y_test]\n",
    "\n",
    "\n",
    "#batch\n",
    "###very important\n",
    "batch_size = 50\n",
    "batch_num = 60000 // batch_size\n",
    "x_train = np.split(np.array(x_train),batch_num)\n",
    "y_train = np.split(np.array(y_train),batch_num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:0.6422  train:0.74\n",
      "test:0.8498  train:0.88\n",
      "test:0.9578  train:0.96\n",
      "test:0.9661  train:0.98\n",
      "test:0.9713  train:1.0\n",
      "test:0.9684  train:1.0\n",
      "test:0.9779  train:1.0\n",
      "test:0.9772  train:1.0\n",
      "test:0.9784  train:1.0\n",
      "test:0.979  train:1.0\n",
      "test:0.9807  train:1.0\n",
      "test:0.9819  train:1.0\n",
      "test:0.9822  train:1.0\n",
      "test:0.9811  train:1.0\n",
      "test:0.9835  train:1.0\n",
      "test:0.9819  train:1.0\n",
      "test:0.9818  train:1.0\n",
      "test:0.9826  train:1.0\n",
      "test:0.9832  train:1.0\n",
      "test:0.9831  train:1.0\n",
      "test:0.9825  train:1.0\n"
     ]
    }
   ],
   "source": [
    "#build network\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#dropout\n",
    "keep_prob=tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.truncated_normal([784,1000],stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([1000])+0.1)\n",
    "L1 = tf.nn.relu(tf.matmul(x,w1)+b1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_prob)\n",
    "\n",
    "w2 = tf.Variable(tf.truncated_normal([1000,1000],stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([1000])+0.1)\n",
    "L2 = tf.nn.relu(tf.matmul(L1,w2)+b2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_prob)\n",
    "\n",
    "w3 = tf.Variable(tf.truncated_normal([1000,10],stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10])+0.1)\n",
    "L3 = tf.matmul(L2,w3)+b3\n",
    "\n",
    "predict = tf.nn.softmax(L3)\n",
    "\n",
    "\n",
    "#loss\n",
    "# loss = tf.reduce_mean(tf.square(y - predict))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=predict))\n",
    "\n",
    "\n",
    "#gradient\n",
    "# train_step = tf.train.GradientDescentOptimizer(0.4).minimize(loss)\n",
    "train_step = tf.train.ProximalGradientDescentOptimizer(0.5).minimize(loss)\n",
    "# train_step = tf.train.AdamOptimizer(1e-2).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#accuracy\n",
    "correct = tf.equal(tf.argmax(y,1),tf.argmax(predict,1))\n",
    "acc = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "\n",
    "\n",
    "#batch\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(batch_num):\n",
    "            sess.run(train_step,feed_dict={x:x_train[batch],y:y_train[batch],keep_prob:0.7})    \n",
    "        test_accuracy = sess.run(acc, feed_dict={x:x_test,y:y_test})\n",
    "        train_accuracy = sess.run(acc, feed_dict={x:x_train[0],y:y_train[0],keep_prob:1.0})\n",
    "        print(\"test:\"+str(test_accuracy)+\"  train:\" +str(train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 test:0.7695  train:0.82 lr:0.001\n",
      "epoch:1 test:0.8567  train:0.88 lr:0.0009\n",
      "epoch:2 test:0.9575  train:0.96 lr:0.00081\n",
      "epoch:3 test:0.9616  train:0.98 lr:0.000729\n",
      "epoch:4 test:0.9609  train:0.98 lr:0.0006561\n",
      "epoch:5 test:0.9635  train:0.98 lr:0.00059049\n",
      "epoch:6 test:0.9674  train:0.98 lr:0.000531441\n",
      "epoch:7 test:0.9698  train:0.98 lr:0.0004782969\n",
      "epoch:8 test:0.9763  train:0.98 lr:0.00043046722\n",
      "epoch:9 test:0.9736  train:1.0 lr:0.0003874205\n",
      "epoch:10 test:0.9762  train:1.0 lr:0.00034867844\n",
      "epoch:11 test:0.9755  train:1.0 lr:0.0003138106\n",
      "epoch:12 test:0.9784  train:1.0 lr:0.00028242954\n",
      "epoch:13 test:0.9772  train:0.98 lr:0.00025418657\n",
      "epoch:14 test:0.9782  train:1.0 lr:0.00022876792\n",
      "epoch:15 test:0.9795  train:1.0 lr:0.00020589113\n",
      "epoch:16 test:0.9807  train:1.0 lr:0.00018530202\n",
      "epoch:17 test:0.98  train:1.0 lr:0.00016677182\n",
      "epoch:18 test:0.981  train:1.0 lr:0.00015009464\n",
      "epoch:19 test:0.9814  train:1.0 lr:0.00013508517\n",
      "epoch:20 test:0.9823  train:1.0 lr:0.00012157665\n"
     ]
    }
   ],
   "source": [
    "#build network\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "lr = tf.Variable(0.001,tf.float32)\n",
    "\n",
    "#dropout\n",
    "keep_prob=tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.truncated_normal([784,1000],stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([1000])+0.1)\n",
    "L1 = tf.nn.relu(tf.matmul(x,w1)+b1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_prob)\n",
    "\n",
    "w2 = tf.Variable(tf.truncated_normal([1000,1000],stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([1000])+0.1)\n",
    "L2 = tf.nn.relu(tf.matmul(L1,w2)+b2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_prob)\n",
    "\n",
    "w3 = tf.Variable(tf.truncated_normal([1000,10],stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10])+0.1)\n",
    "L3 = tf.matmul(L2,w3)+b3\n",
    "\n",
    "predict = tf.nn.softmax(L3)\n",
    "\n",
    "\n",
    "#loss\n",
    "# loss = tf.reduce_mean(tf.square(y - predict))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=predict))\n",
    "\n",
    " \n",
    "#gradient\n",
    "# train_step = tf.train.GradientDescentOptimizer(0.4).minimize(loss)\n",
    "# train_step = tf.train.ProximalGradientDescentOptimizer(0.5).minimize(loss)\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#accuracy\n",
    "correct = tf.equal(tf.argmax(y,1),tf.argmax(predict,1))\n",
    "acc = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "\n",
    "\n",
    "#batch\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        sess.run(tf.assign(lr,0.001 * (0.9 ** epoch)))\n",
    "        for batch in range(batch_num):\n",
    "            sess.run(train_step,feed_dict={x:x_train[batch],y:y_train[batch],keep_prob:0.7})\n",
    "        for batch in range(batch_num):\n",
    "            sess.run(train_step,feed_dict={x:x_train[batch],y:y_train[batch],keep_prob:0.5})    \n",
    "        lrp = sess.run(lr)    \n",
    "        test_accuracy = sess.run(acc, feed_dict={x:x_test,y:y_test})\n",
    "        train_accuracy = sess.run(acc, feed_dict={x:x_train[0],y:y_train[0],keep_prob:1.0})\n",
    "        print(\"epoch:\" +str(epoch) +\" test:\"+str(test_accuracy)+\"  train:\" +str(train_accuracy) + \" lr:\" + str(lrp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
