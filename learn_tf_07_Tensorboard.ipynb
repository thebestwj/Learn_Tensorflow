{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6132153835517425049\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1453034700\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16763176596825618802\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 750 Ti, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(x_trainx, y_train), (x_testx, y_test) = mnist\n",
    "\n",
    "x_train = np.reshape(x_trainx,(60000,784))\n",
    "x_test = np.reshape(x_testx,(10000,784))\n",
    "\n",
    "#regulazation\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "y_train = np.eye(10)[y_train]\n",
    "y_test = np.eye(10)[y_test]\n",
    "\n",
    "\n",
    "#batch\n",
    "###very important\n",
    "batch_size = 100\n",
    "batch_num = 60000 // batch_size\n",
    "x_train = np.split(np.array(x_train),batch_num)\n",
    "y_train = np.split(np.array(y_train),batch_num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:0.9178  train:0.96\n",
      "test:0.9435  train:0.96\n",
      "test:0.9562  train:0.96\n",
      "test:0.9613  train:0.96\n",
      "test:0.9656  train:0.97\n",
      "test:0.9678  train:0.97\n",
      "test:0.9702  train:0.97\n",
      "test:0.9709  train:0.97\n",
      "test:0.9718  train:0.99\n",
      "test:0.9717  train:0.99\n",
      "test:0.9711  train:0.99\n",
      "test:0.9726  train:0.99\n",
      "test:0.9728  train:0.99\n",
      "test:0.9742  train:0.99\n",
      "test:0.9735  train:0.99\n",
      "test:0.973  train:0.99\n",
      "test:0.9747  train:0.99\n",
      "test:0.9748  train:0.99\n",
      "test:0.9756  train:0.99\n",
      "test:0.9762  train:0.99\n",
      "test:0.9755  train:0.99\n"
     ]
    }
   ],
   "source": [
    "#build network\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32,[None,784])\n",
    "    y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#dropout\n",
    "keep_prob=tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.name_scope('L1'):\n",
    "    w1 = tf.Variable(tf.truncated_normal([784,200],stddev=0.1))\n",
    "    b1 = tf.Variable(tf.zeros([200])+0.1)\n",
    "    L1 = tf.nn.relu(tf.matmul(x,w1)+b1)\n",
    "    L1_drop = tf.nn.dropout(L1,keep_prob)\n",
    "\n",
    "with tf.name_scope('L2'):\n",
    "    w2 = tf.Variable(tf.truncated_normal([200,200],stddev=0.1))\n",
    "    b2 = tf.Variable(tf.zeros([200])+0.1)\n",
    "    L2 = tf.nn.relu(tf.matmul(L1,w2)+b2)\n",
    "    L2_drop = tf.nn.dropout(L2,keep_prob)\n",
    "\n",
    "with tf.name_scope('L3'):\n",
    "    w3 = tf.Variable(tf.truncated_normal([200,10],stddev=0.1))\n",
    "    b3 = tf.Variable(tf.zeros([10])+0.1)\n",
    "    L3 = tf.matmul(L2,w3)+b3\n",
    "\n",
    "with tf.name_scope('softmax'):\n",
    "    predict = tf.nn.softmax(L3)\n",
    "\n",
    "\n",
    "#loss\n",
    "# loss = tf.reduce_mean(tf.square(y - predict))\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=predict))\n",
    "\n",
    "\n",
    "#gradient\n",
    "# train_step = tf.train.GradientDescentOptimizer(0.4).minimize(loss)\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.ProximalGradientDescentOptimizer(0.5).minimize(loss)\n",
    "# train_step = tf.train.AdamOptimizer(1e-2).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#accuracy\n",
    "correct = tf.equal(tf.argmax(y,1),tf.argmax(predict,1))\n",
    "acc = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "\n",
    "\n",
    "#batch\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter(\"logs/\",sess.graph)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(batch_num):\n",
    "            sess.run(train_step,feed_dict={x:x_train[batch],y:y_train[batch],keep_prob:0.7})\n",
    "        with tf.name_scope('acc'):    \n",
    "            test_accuracy = sess.run(acc, feed_dict={x:x_test,y:y_test})\n",
    "            train_accuracy = sess.run(acc, feed_dict={x:x_train[0],y:y_train[0],keep_prob:1.0})\n",
    "            print(\"test:\"+str(test_accuracy)+\"  train:\" +str(train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
